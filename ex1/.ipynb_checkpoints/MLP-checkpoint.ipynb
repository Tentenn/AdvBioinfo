{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c70366f-5985-4124-8ca9-a6b86e8a204c",
   "metadata": {},
   "source": [
    "### Most of the information presented in this notebook orginated from the resource linked below, even if they have been modified\n",
    "[taken from here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "\n",
    "more useful links:\n",
    "+ [Scikit Learn Get Started](https://scikit-learn.org/stable/getting_started.html)\n",
    "+ [Scikit Learn Neural Networks](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6597e5-fef2-4ffc-b563-055874c5d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind of standard import\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae13d1d5-c7f0-444e-836b-e6b8cb1da113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03838405 0.96161595]]\n",
      "[1 0 1 0 1]\n",
      "0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier  # the neural network \n",
    "from sklearn.datasets import make_classification # easy generation of synthetic input data\n",
    "from sklearn.model_selection import train_test_split # to conveniantly split the data into test and training \n",
    "X, y = make_classification(n_samples=100, random_state=1) # 100 points, default: 20 features, 2 classes\n",
    "\n",
    "# the use of X for the input feature data (2D array) and y (1D) for the target values (prediction goal) is convention\n",
    "# we fix the random_state to make multiple run reproducible\n",
    "# we use stratify=y to have the same class ratios in the training and in the testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    random_state=1)\n",
    "# the call to fit with the provided training data is the standard way to train a model in sklearn\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "\n",
    "# prints out the probability for each of the classes\n",
    "# here only the first test instance is used [:1] (slicing)\n",
    "print(clf.predict_proba(X_test[:1]))\n",
    "\n",
    "# here we predict the class of the first 5 test instances\n",
    "print(clf.predict(X_test[:5, :]))\n",
    "\n",
    "# the performance on the complete test set\n",
    "print(clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b8bed-eab1-4547-b59e-eb0351497c27",
   "metadata": {},
   "source": [
    "If you have no internet connection or do not fire up your browser there is an easy way to access the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bc294-f3b0-4149-9ae9-a56b663b6697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721357e-feee-4b57-aeeb-adfd48087168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(make_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8196236-daa3-42ab-8d24-b4012f287e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b310105-e883-45b5-98d9-894d817a4d51",
   "metadata": {},
   "source": [
    "The follwing example allows to demonstrate overfitting. The training is stopped after every epoche (max_iter=1) and the performance on the training and on the testing set is determined. We can observe that up to a certain number of epoches the score both on the training and the testing set is improving. In this phase the model is generalizing (i.e. learning) well, but after some point the performance on the training set continues to improve where on the testing set is getting worse again. This is the point where overfitting starts, i.e. the model do not generalize anymore but picks up training set specific information, i.e. it is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f89778-ee48-4d6a-b506-ce2982a680ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=1, solver='adam', warm_start=True)\n",
    "for i in range(300):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"epoche: \" + str(i))\n",
    "    print(\"Score on training set:\" + str (clf.score(X_train, y_train)))\n",
    "    print(\"Score on testing set:\" + str (clf.score(X_test, y_test)))\n",
    "    print(clf.loss_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677447bf-5789-4aeb-a8f7-adb9efdf8e49",
   "metadata": {},
   "source": [
    "This allows you to retrieve the weights of a trained model. Apart from showing the final weights this is not very suitable to easily derive the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513d9e9-1190-4414-b2f8-1ea628d38d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb806ff1-1bca-4589-b1a4-d000284df0fc",
   "metadata": {},
   "source": [
    "The following example should demonstrate the use of the early_stopping feature which actually stops early before overfitting. Unfortunately it is still far from optimal in this case here. Looking at the information obtain with the verbose option set, it looks like that the rather small validation set of 10 instances is quite stable in the predictions and triggers so the termination. You can explore this by e.g. setting n_iter_no_change to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836a951-692a-4843-a8d7-a935725fafaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=300\n",
    "                    ,early_stopping=True\n",
    "                    #,tol=1e-10\n",
    "                    ,verbose=True\n",
    "                    #,n_iter_no_change=50\n",
    "                   ).fit(X_train, y_train)\n",
    "print(clf.predict_proba(X_test[:1]))\n",
    "\n",
    "print(clf.predict(X_test[:5, :]))\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "print(clf.n_iter_)\n",
    "print(clf.loss_curve_) # See how the loss on the training set decreases over the epoches\n",
    "print(clf.best_validation_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92760653-91bf-4b56-aa00-2220eec4b865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
